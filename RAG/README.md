**RAG (Retrieval-Augmented Generation, 검색 증강 생성)**는 쉽게 말해 **"AI에게 오픈북 테스트를 보게 하는 기술"**입니다.

대규모 언어 모델(LLM)이 자신이 학습한 지식에만 의존해서 답하는 것이 아니라, 외부의 믿을 수 있는 데이터(문서, DB 등)를 찾아서(Retrieval) 그 내용을 참고해(Augmented) 답변을 생성(Generation)하는 방식입니다.

1. temperature (온도)란 무엇인가요?
   한마디로: "AI의 창의성 조절 레버"입니다.

값 (0 ~ 1 사이):

0에 가까울수록 (0): AI가 가장 확률이 높은 단어만 선택합니다. 답변이 논리적, 사실적, 일관성 있게 나옵니다. 정해진 문서 내용을 바탕으로 답해야 하는 RAG에서는 보통 0을 사용합니다.

1에 가까울수록: AI가 확률이 낮은 단어도 선택해 봅니다. 답변이 창의적, 다양해지지만, 엉뚱한 소리(환각, Hallucination)를 할 위험이 커집니다.

코드 적용: 작성하신 코드에서는 temperature=0으로 설정했기 때문에, AI가 지어내지 않고 문서에 근거한 딱딱한 팩트 위주로 답변하게 됩니다.

2. 임베딩 모델(Embedding Model)이란?
   한마디로: "텍스트 번역기 (사람 언어 → 컴퓨터 언어)"입니다.

컴퓨터는 '사과', '바나나'라는 글자의 의미를 모릅니다. 대신 이를 **숫자의 나열(벡터)**로 바꿔주면 계산할 수 있습니다.

역할: 텍스트를 수백, 수천 개의 숫자로 된 좌표값(Vector)으로 변환합니다.

특징: 의미가 비슷한 단어는 좌표상에서 서로 가까운 위치에 놓이게 됩니다. (예: '왕'과 '남자'의 거리 ≈ '여왕'과 '여자'의 거리)

코드 적용: GoogleGenerativeAIEmbeddings가 PDF의 문장들을 컴퓨터가 이해하고 검색할 수 있는 숫자로 바꿔주는 역할을 합니다.

3. 문서를 학습시키는 이유는 RAG를 테스트 하기 위함?
   정확히는: "학습(Training)"이 아니라 "참조(Reference)"입니다.

이 부분이 가장 많이 혼동하시는 부분입니다.

학습(Fine-tuning): AI의 뇌 자체를 개조해서 지식을 영구적으로 기억시키는 것 (공부해서 시험 보기). 시간이 오래 걸리고 비쌉니다.

RAG (작성하신 코드): AI에게 교과서를 옆에 펴두고 **"오픈북 테스트"**를 보게 하는 것. AI 모델 자체는 변하지 않지만, 질문이 들어올 때마다 관련 페이지를 찾아서 읽고 답해줍니다.

이유: 문서를 로드하는 이유는 AI가 그 문서를 영구적으로 배우는 게 아니라, 질문이 들어왔을 때 찾아볼 데이터베이스(도서관)를 구축하기 위함입니다.

4. 텍스트 스플리팅(Text Splitting)은 왜 하나요?
   한마디로: "너무 큰 덩어리는 한입에 못 먹으니까 자르는 것"입니다.

AI의 한계: AI 모델은 한 번에 읽을 수 있는 글자 수(Context Window)에 제한이 있습니다. 책 전체를 한 번에 다 넣을 수 없습니다.

검색 정확도: 질문과 관련된 내용은 책 전체가 아니라 특정 문단에 있습니다. 잘게 쪼개놔야 질문과 가장 관련 있는 **'핵심 조각'**만 쏙 뽑아서 AI에게 줄 수 있습니다.

코드 적용: RecursiveCharacterTextSplitter를 사용하여 문맥이 끊기지 않게 의미 단위로 1000자씩 자른 것입니다.

5. 벡터 DB(Chroma)와 임베딩의 연관 관계?
   한마디로: "도서관(Chroma)과 분류 시스템(임베딩)"의 관계입니다.

임베딩: 책 내용을 숫자로 변환하는 '변환 과정' 혹은 **'도구'**입니다.

벡터 DB (Chroma): 변환된 숫자들을 저장하고, 나중에 질문이 들어왔을 때 비슷한 숫자를 아주 빠르게 찾아주는 **'저장소'**입니다.

관계: 임베딩 없이는 벡터 DB에 데이터를 넣을 수 없습니다. (숫자가 없으니까요). 반대로 벡터 DB가 없으면 매번 문서를 다시 임베딩해야 하므로 속도가 매우 느려집니다.

코드 흐름: 문서를 자른다 -> 임베딩 모델로 숫자로 바꾼다 -> Chroma DB에 저장한다.

6. 랭체인(LangChain)이란?
   한마디로: "이 모든 부품을 연결하는 파이프라인(배관) 혹은 접착제"입니다.

RAG를 만들려면 위에서 말한 LLM, 임베딩, 벡터 DB, 문서 로더 등 다양한 도구가 필요합니다. 이 도구들은 서로 제조사도 다르고 사용법도 다릅니다.

역할: 이 서로 다른 도구들을 표준화된 방식으로 쉽게 연결(Chain)해주는 파이썬 라이브러리입니다.

코드 적용:

Python

# 랭체인이 없다면 이 과정을 수동으로 코딩해야 해서 매우 복잡합니다.

rag_chain = retriever | prompt | llm | parser
위 코드처럼 | 기호 하나로 검색기, 프롬프트, AI 모델을 순서대로 연결해주는 것이 바로 랭체인의 마법입니다.
